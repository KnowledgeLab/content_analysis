{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This needs to be organized\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "\n",
    "import nltk\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.parse import stanford\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw.tree import TreeView\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import graphviz\n",
    "import re\n",
    "\n",
    "import IPython.display\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To using the [Stanford NLP group](http://nlp.stanford.edu/) programs with nltk requires a bit of setup. We are basing these instructions on those provided by nltk, [here](https://github.com/nltk/nltk/wiki/Installing-Third-Party-Software#stanford-tagger-ner-tokenizer-and-parser), but with a couple of changes for the notebooks.\n",
    "\n",
    "1. Install [Java 1.8+](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n",
    "    + Make sure your `JAVAPATH` is setup if you're on windows\n",
    "2. Download the following zip files from the Stanford NLP group, where DATE is the release date of the files, this will be the value of `stanfordVersion`\n",
    "    + [`stanford-corenlp-full-2016-10-31.zip`](https://stanfordnlp.github.io/CoreNLP/)\n",
    "    + [`stanford-postagger-full-DATE.zip`](http://nlp.stanford.edu/software/tagger.html#Download)\n",
    "    + [`stanford-ner-DATE.zip`](http://nlp.stanford.edu/software/CRF-NER.html#Download)\n",
    "    + [`stanford-parser-full-DATE.zip`](http://nlp.stanford.edu/software/lex-parser.html#Download)\n",
    "3. Unzip the files and place the resulting directories in the same location, this will become `stanfordDir`\n",
    "4. Lookup the version number used by the parser `stanford-parser-VERSION-models.jar` and set to to be `parserVersion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the date at the end of each of the zip files, e.g.\n",
    "#the date in stanford-ner-2016-10-31.zip\n",
    "stanfordVersion = '2016-10-31'\n",
    "\n",
    "#This is the version numbers of the parser models, these\n",
    "#are files in `stanford-parser-full-2016-10-31.zip`, e.g.\n",
    "#stanford-parser-3.7.0-models.jar\n",
    "parserVersion = '3.7.0'\n",
    "\n",
    "#This is where the zip files were unzipped.Make sure to\n",
    "#unzip into directories named after the zip files\n",
    "#Don't just put all the files in `stanford-NLP`\n",
    "stanfordDir = '/mnt/efs/resources/shared/stanford-NLP'\n",
    "\n",
    "#Parser model, there are a few for english and a couple of other languages as well\n",
    "modelName = 'englishPCFG.ser.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now will initialize all the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up [NER tagger](http://www.nltk.org/api/nltk.tag.html?highlight=stanfordpostagger#nltk.tag.stanford.StanfordNERTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nerClassifierPath = os.path.join(stanfordDir,'stanford-ner-{}'.format(stanfordVersion), 'classifiers/english.all.3class.distsim.crf.ser.gz')\n",
    "\n",
    "nerJarPath = os.path.join(stanfordDir,'stanford-ner-{}'.format(stanfordVersion), 'stanford-ner.jar')\n",
    "\n",
    "nerTagger = StanfordNERTagger(nerClassifierPath, nerJarPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up [POS Tagger](http://www.nltk.org/api/nltk.tag.html?highlight=stanfordpostagger#nltk.tag.stanford.StanfordPOSTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postClassifierPath = os.path.join(stanfordDir, 'stanford-postagger-full-{}'.format(stanfordVersion), 'models/english-bidirectional-distsim.tagger')\n",
    "\n",
    "postJarPath = os.path.join(stanfordDir,'stanford-postagger-full-{}'.format(stanfordVersion), 'stanford-postagger.jar')\n",
    "\n",
    "postTagger = StanfordPOSTagger(postClassifierPath, postJarPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up [Parser](http://www.nltk.org/api/nltk.parse.html?highlight=stanfordparser#module-nltk.parse.stanford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parserJarPath = os.path.join(stanfordDir, 'stanford-parser-full-{}'.format(stanfordVersion), 'stanford-parser.jar')\n",
    "\n",
    "parserModelsPath = os.path.join(stanfordDir, 'stanford-parser-full-{}'.format(stanfordVersion), 'stanford-parser-{}-models.jar'.format(parserVersion))\n",
    "\n",
    "modelPath = os.path.join(stanfordDir, 'stanford-parser-full-{}'.format(stanfordVersion), modelName)\n",
    "\n",
    "#The model files are stored in the jar, we need to extract them for nltk to use\n",
    "if not os.path.isfile(modelPath):\n",
    "    with zipfile.ZipFile(parserModelsPath) as zf:\n",
    "        with open(modelPath, 'wb') as f:\n",
    "            f.write(zf.read('edu/stanford/nlp/models/lexparser/{}'.format(modelName)))\n",
    "\n",
    "parser = stanford.StanfordParser(parserJarPath, parserModelsPath, modelPath)\n",
    "\n",
    "depParser = stanford.StanfordDependencyParser(parserJarPath, parserModelsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information extraction, this isn't yet supported by nltk so we will be defining our own function. `openIE()` takes in a string or list of strings and produces all the subject, verb, object triples stanford corenlp can find, as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Watch out, this will very rarely raise an error since it trusts stanford-corenlp \n",
    "def openIE(target):\n",
    "    if isinstance(target, list):\n",
    "        target = '\\n'.join(target)\n",
    "    #setup the java targets\n",
    "    coreDir = '{}/stanford-corenlp-full-{}'.format(stanfordDir, stanfordVersion)\n",
    "    cp = '{0}/stanford-corenlp-{1}.jar:{0}/stanford-corenlp-{1}-models.jar:CoreNLP-to-HTML.xsl:slf4j-api.jar:slf4j-simple.jar'.format(coreDir, parserVersion)\n",
    "    with tempfile.NamedTemporaryFile(mode = 'w', delete = False) as f:\n",
    "        #Core nlp requires a files, so we will make a temp one to pass to it\n",
    "        #This file should be deleted by the OS soon after it has been used\n",
    "        f.write(target)\n",
    "        f.seek(0)\n",
    "        print(\"Starting OpenIE run\")\n",
    "        sp = subprocess.run(['java', '-mx2g', '-cp', cp, 'edu.stanford.nlp.naturalli.OpenIE', '-threads', '1', f.name], stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "        #Live stderr is non-trivial so this is the best we can do\n",
    "        print(sp.stderr.decode('utf-8'))\n",
    "        retSting = sp.stdout.decode('utf-8')\n",
    "    #Making the DataFrame, again having to pass a fake file, yay POSIX I guess\n",
    "    with io.StringIO(retSting) as f:\n",
    "        df = pandas.read_csv(f, delimiter = '\\t', names =['certainty', 'subject', 'verb', 'object'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test these tools on a short example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the elephant in my pajamas.\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.\n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [word_tokenize(t) for t in text]\n",
    "print('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'PRP'), ('saw', 'VBD'), ('the', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NNS'), ('.', '.')], [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')], [('While', 'IN'), ('in', 'IN'), ('France', 'NNP'), (',', ','), ('Christine', 'NNP'), ('Lagarde', 'NNP'), ('discussed', 'VBD'), ('short-term', 'JJ'), ('stimulus', 'NN'), ('efforts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Wall', 'NNP'), ('Street', 'NNP'), ('Journal', 'NNP'), ('.', '.')], [('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "pos_sents = postTagger.tag_sents(tokenized_text)\n",
    "print(posSents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named-Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'O'), ('saw', 'O'), ('the', 'O'), ('elephant', 'O'), ('in', 'O'), ('my', 'O'), ('pajamas', 'O'), ('.', 'O')], [('The', 'O'), ('quick', 'O'), ('brown', 'O'), ('fox', 'O'), ('jumped', 'O'), ('over', 'O'), ('the', 'O'), ('lazy', 'O'), ('dog', 'O'), ('.', 'O')], [('While', 'O'), ('in', 'O'), ('France', 'LOCATION'), (',', 'O'), ('Christine', 'PERSON'), ('Lagarde', 'PERSON'), ('discussed', 'O'), ('short-term', 'O'), ('stimulus', 'O'), ('efforts', 'O'), ('in', 'O'), ('a', 'O'), ('recent', 'O'), ('interview', 'O'), ('with', 'O'), ('the', 'O'), ('Wall', 'ORGANIZATION'), ('Street', 'ORGANIZATION'), ('Journal', 'ORGANIZATION'), ('.', 'O')], [('Buffalo', 'LOCATION'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O'), ('buffalo', 'O'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "classified_sents = nerTagger.tag_sents(tokenized_text)\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('PRP', ['I'])]), Tree('VP', [Tree('VBD', ['saw']), Tree('NP', [Tree('DT', ['the']), Tree('NN', ['elephant'])]), Tree('PP', [Tree('IN', ['in']), Tree('NP', [Tree('PRP$', ['my']), Tree('NNS', ['pajamas'])])])]), Tree('.', ['.'])])])]\n"
     ]
    }
   ],
   "source": [
    "parses = list(parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "fistSentParseTree = list(parses[0]) #iterators so be careful about re-running code, without re-running this block\n",
    "print(fistSentParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want the tree looking a bit nicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ROOT                           \n",
      "                   |                              \n",
      "                   S                             \n",
      "  _________________|___________________________   \n",
      " |                 VP                          | \n",
      " |    _____________|__________                 |  \n",
      " |   |       |                PP               | \n",
      " |   |       |             ___|____            |  \n",
      " NP  |       NP           |        NP          | \n",
      " |   |    ___|_____       |    ____|_____      |  \n",
      "PRP VBD  DT        NN     IN PRP$       NNS    . \n",
      " |   |   |         |      |   |          |     |  \n",
      " I  saw the     elephant  in  my      pajamas  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fistSentParseTree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Or another sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ROOT                                     \n",
      "                           |                                        \n",
      "                           NP                                      \n",
      "            _______________|_____________________________           \n",
      "           NP                      NP                    NP        \n",
      "    _______|_______         _______|_______         _____|_____     \n",
      "  NNP     NNP     NNP      JJ      JJ      NN     NNP         NNP  \n",
      "   |       |       |       |       |       |       |           |    \n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo     buffalo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list(parses[3])[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also work on the un tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x111aaaea0>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'quick'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'brown'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [2, 3],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'fox'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'nmod': [9],\n",
      "                                      'nsubj': [4]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 0,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'jumped'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'over'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'lazy'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [8],\n",
      "                                      'case': [6],\n",
      "                                      'det': [7]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nmod',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'dog'}})\n"
     ]
    }
   ],
   "source": [
    "depParses = list(depParser.raw_parse_sents(text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "secondSentDepParseTree = list(depParses[1])[0] #iterators so be careful about re-running code, without re-running this block\n",
    "print(secondSentDepParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a graph and we can convert it to a dot file and use that to visulize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"472pt\" height=\"308pt\"\n",
       " viewBox=\"0.00 0.00 472.00 308.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 304)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-304 468,-304 468,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (jumped)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254,-263.597C254,-251.746 254,-235.817 254,-222.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"257.5,-222.084 254,-212.084 250.5,-222.084 257.5,-222.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"265.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (fox)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M229.205,-175.803C210.197,-162.62 183.785,-144.302 162.992,-129.882\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164.964,-126.99 154.752,-124.167 160.975,-132.742 164.964,-126.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node7\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"321\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (dog)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M267.558,-175.597C277.248,-163.159 290.437,-146.23 301.288,-132.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.306,-134.124 307.69,-124.084 298.784,-129.822 304.306,-134.124\"/>\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"29\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (The)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (quick)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"198\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (brown)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.561,-87.5966C94.4032,-74.6899 73.5641,-56.9457 56.8783,-42.7379\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.9467,-39.9022 49.0638,-36.084 54.4085,-45.2319 58.9467,-39.9022\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.953,-87.5966C123.169,-75.6285 119.419,-59.5011 116.254,-45.8907\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.647,-45.0313 113.973,-36.084 112.829,-46.6169 119.647,-45.0313\"/>\n",
       "<text text-anchor=\"middle\" x=\"138\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M143.705,-87.9364C148.264,-82.2416 153.361,-75.8558 158,-70 164.708,-61.5322 172.009,-52.2434 178.517,-43.9401\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.299,-46.0638 184.708,-36.0322 175.787,-41.7487 181.299,-46.0638\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"283\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (over)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;6 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>9&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M313.31,-87.5966C307.97,-75.5112 300.756,-59.1844 294.705,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.792,-43.8163 290.549,-36.084 291.389,-46.6455 297.792,-43.8163\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.5\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"359\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (the)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.69,-87.5966C334.03,-75.5112 341.244,-59.1844 347.295,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"350.611,-46.6455 351.451,-36.084 344.208,-43.8163 350.611,-46.6455\"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"434\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (lazy)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.596,-87.8033C360.764,-74.7375 384.559,-56.6277 403.428,-42.2673\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"405.606,-45.0083 411.444,-36.1669 401.366,-39.438 405.606,-45.0083\"/>\n",
       "<text text-anchor=\"middle\" x=\"404\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x111b10630>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondSentGraph = graphviz.Source(secondSentDepParseTree.to_dot())\n",
    "secondSentGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"394pt\" height=\"308pt\"\n",
       " viewBox=\"0.00 0.00 394.00 308.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 304)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-304 390,-304 390,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node2\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (Buffalo)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;3 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179,-263.597C179,-251.746 179,-235.817 179,-222.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.5,-222.084 179,-212.084 175.5,-222.084 182.5,-222.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (Buffalo)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.597,-186.774C117.944,-181.81 91.5878,-173.087 72,-158 63.5666,-151.504 56.6533,-142.203 51.3724,-133.317\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.3339,-131.438 46.4649,-124.343 48.1923,-134.797 54.3339,-131.438\"/>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (buffalo)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.935,-175.778C150.546,-170.645 145.395,-164.606 142,-158 138.307,-150.815 136.349,-142.346 135.362,-134.395\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.848,-134.08 134.558,-124.393 131.87,-134.641 138.848,-134.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"172\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node5\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (buffalo)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;6 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.741,-175.727C194.439,-170.131 198.476,-163.856 202,-158 206.792,-150.038 211.755,-141.212 216.149,-133.171\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"219.326,-134.653 221,-124.192 213.167,-131.326 219.326,-134.653\"/>\n",
       "<text text-anchor=\"middle\" x=\"220.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node6\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"326\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (buffalo)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;8 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.394,-175.803C231.303,-162.401 263.284,-143.691 288.113,-129.165\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290.043,-132.091 296.907,-124.02 286.509,-126.049 290.043,-132.091\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node7\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (buffalo)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>6&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M210.775,-87.5966C196.647,-74.8072 177.273,-57.2679 161.651,-43.1263\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.634,-40.2005 153.872,-36.084 158.936,-45.39 163.634,-40.2005\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node8\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (buffalo)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;5 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230,-87.5966C230,-75.7459 230,-59.8169 230,-46.2917\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.5,-46.084 230,-36.084 226.5,-46.084 233.5,-46.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"326\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (Buffalo)</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326,-87.5966C326,-75.7459 326,-59.8169 326,-46.2917\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"329.5,-46.084 326,-36.084 322.5,-46.084 329.5,-46.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x111b21390>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(list(depParses[3])[0].to_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "Adding annotator tokenize\n",
      "Adding annotator ssplit\n",
      "Adding annotator pos\n",
      "Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.6 sec].\n",
      "Adding annotator lemma\n",
      "Adding annotator depparse\n",
      "Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "PreComputed 99996, Elapsed Time: 12.354 (s)\n",
      "Initializing dependency parser ... done [13.6 sec].\n",
      "Adding annotator natlog\n",
      "Adding annotator openie\n",
      "Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0064 seconds]\n",
      "Processing file: /var/folders/lk/cq97m8gs5_z62sdfszp2x9jw0000gn/T/tmp9gvi3y24\n",
      "All files have been queued; awaiting termination...\n",
      "DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ieDF = openIE(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`openIE()` prints everything stanford core produces and we can see from looking at it that initializing the dependency parser takes most of the time, so calling the function will always take atleast 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>elephant</td>\n",
       "      <td>is in</td>\n",
       "      <td>my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant in my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed stimulus efforts in</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent intervie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview with Wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "      <td>is in</td>\n",
       "      <td>recent interview with Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview with Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>recent interview</td>\n",
       "      <td>is with</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certainty                      subject                           verb  \\\n",
       "0         1.0                     elephant                          is in   \n",
       "1         1.0                            I                            saw   \n",
       "2         1.0                            I                            saw   \n",
       "3         1.0              quick brown fox                    jumped over   \n",
       "4         1.0              quick brown fox                    jumped over   \n",
       "5         1.0                    quick fox                    jumped over   \n",
       "6         1.0                          fox                    jumped over   \n",
       "7         1.0                    brown fox                    jumped over   \n",
       "8         1.0                    brown fox                    jumped over   \n",
       "9         1.0                    quick fox                    jumped over   \n",
       "10        1.0                          fox                    jumped over   \n",
       "11        1.0            Christine Lagarde                      discussed   \n",
       "12        1.0            Christine Lagarde                      discussed   \n",
       "13        1.0            Christine Lagarde                      discussed   \n",
       "14        1.0            Christine Lagarde  discussed stimulus efforts in   \n",
       "15        1.0            Christine Lagarde                      discussed   \n",
       "16        1.0            Christine Lagarde                      discussed   \n",
       "17        1.0            Christine Lagarde                      discussed   \n",
       "18        1.0  short-term stimulus efforts                          is in   \n",
       "19        1.0            Christine Lagarde                      discussed   \n",
       "20        1.0            Christine Lagarde                      discussed   \n",
       "21        1.0            Christine Lagarde                      discussed   \n",
       "22        1.0            Christine Lagarde                      discussed   \n",
       "23        1.0             recent interview                        is with   \n",
       "\n",
       "                                               object  \n",
       "0                                          my pajamas  \n",
       "1                              elephant in my pajamas  \n",
       "2                                            elephant  \n",
       "3                                            lazy dog  \n",
       "4                                                 dog  \n",
       "5                                                 dog  \n",
       "6                                                 dog  \n",
       "7                                            lazy dog  \n",
       "8                                                 dog  \n",
       "9                                            lazy dog  \n",
       "10                                           lazy dog  \n",
       "11  short-term stimulus efforts in interview with ...  \n",
       "12                      stimulus efforts in interview  \n",
       "13               stimulus efforts in recent interview  \n",
       "14                                             France  \n",
       "15  short-term stimulus efforts in recent intervie...  \n",
       "16  stimulus efforts in recent interview with Wall...  \n",
       "17    short-term stimulus efforts in recent interview  \n",
       "18          recent interview with Wall Street Journal  \n",
       "19  stimulus efforts in interview with Wall Street...  \n",
       "20                                   stimulus efforts  \n",
       "21                        short-term stimulus efforts  \n",
       "22           short-term stimulus efforts in interview  \n",
       "23                                Wall Street Journal  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No buffalos, but the rest looks good "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with a bigger corpus. We will look at a few of the top posts from the reddit data we used last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditDF = pandas.read_csv('data/reddit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the 10 highest scoring posts and tokenizing the sentences. Notice, we aren't going to do any kind of stemming this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>over_18</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>brenkelieshere</td>\n",
       "      <td>False</td>\n",
       "      <td>9448</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Last year, Help Desk got a call from a user co...</td>\n",
       "      <td>How to fix a laptop that won't boot in under a...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Last, year, ,, Help, Desk, got, a, call, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Bombadils</td>\n",
       "      <td>False</td>\n",
       "      <td>10528</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>First post in quite some time! I work at a loc...</td>\n",
       "      <td>OK, now the password is 'D35p41r'</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[First, post, in, quite, some, time, !], [I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1200</td>\n",
       "      <td>whenlifegivesyoushit</td>\n",
       "      <td>False</td>\n",
       "      <td>11003</td>\n",
       "      <td>Relationships</td>\n",
       "      <td>[Original Post](https://www.reddit.com/r/relat...</td>\n",
       "      <td>[UPDATE]My [26 F] with my husband [29 M] 1 yea...</td>\n",
       "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
       "      <td>[[[, Original, Post, ], (, https, :, //www.red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>sfsdfd</td>\n",
       "      <td>False</td>\n",
       "      <td>11295</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>I witnessed this astounding IT meltdown around...</td>\n",
       "      <td>Company-wide email + 30,000 employees + auto-r...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[I, witnessed, this, astounding, IT, meltdown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Raitaro</td>\n",
       "      <td>False</td>\n",
       "      <td>12372</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>I work Helpdesk for a retail store chain in th...</td>\n",
       "      <td>I'm pretty sure I knocked a user out from near...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[I, work, Helpdesk, for, a, retail, store, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>goldie-gold</td>\n",
       "      <td>False</td>\n",
       "      <td>12650</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>This just happened...  So, I had a laptop syst...</td>\n",
       "      <td>Engineer is doing drugs!! No. No they aren't.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[This, just, happened, ...], [So, ,, I, had, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TheDroolinFool</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Another tale from the out of hours IT desk... ...</td>\n",
       "      <td>\"I need you to fix Google Bing immediately!\"</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Another, tale, from, the, out, of, hours, IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Clickity_clickity</td>\n",
       "      <td>False</td>\n",
       "      <td>13404</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>[Part 1](http://www.reddit.com/r/talesfromtech...</td>\n",
       "      <td>Jack, the Worst End User, Part 4</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[[, Part, 1, ], (, http, :, //www.reddit.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SECGaz</td>\n",
       "      <td>False</td>\n",
       "      <td>13724</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>&gt; $Me  - Hello, IT.   &gt; $Usr - Hi, I am still ...</td>\n",
       "      <td>Hi, I am still off sick but I am not.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[&gt;, $, Me, -, Hello, ,, IT, .], [&gt;, $, Usr, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>guitarsdontdance</td>\n",
       "      <td>False</td>\n",
       "      <td>14089</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>So my story starts on what was a normal day ta...</td>\n",
       "      <td>\"Don't bother sending a tech, I'll be dead by ...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[So, my, story, starts, on, what, was, a, nor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                author over_18  score                subreddit  \\\n",
       "9           8        brenkelieshere   False   9448  Tales From Tech Support   \n",
       "8           7             Bombadils   False  10528  Tales From Tech Support   \n",
       "7        1200  whenlifegivesyoushit   False  11003            Relationships   \n",
       "6           6                sfsdfd   False  11295  Tales From Tech Support   \n",
       "5           5               Raitaro   False  12372  Tales From Tech Support   \n",
       "4           4           goldie-gold   False  12650  Tales From Tech Support   \n",
       "3           3        TheDroolinFool   False  13152  Tales From Tech Support   \n",
       "2           2     Clickity_clickity   False  13404  Tales From Tech Support   \n",
       "1           1                SECGaz   False  13724  Tales From Tech Support   \n",
       "0           0      guitarsdontdance   False  14089  Tales From Tech Support   \n",
       "\n",
       "                                                text  \\\n",
       "9  Last year, Help Desk got a call from a user co...   \n",
       "8  First post in quite some time! I work at a loc...   \n",
       "7  [Original Post](https://www.reddit.com/r/relat...   \n",
       "6  I witnessed this astounding IT meltdown around...   \n",
       "5  I work Helpdesk for a retail store chain in th...   \n",
       "4  This just happened...  So, I had a laptop syst...   \n",
       "3  Another tale from the out of hours IT desk... ...   \n",
       "2  [Part 1](http://www.reddit.com/r/talesfromtech...   \n",
       "1  > $Me  - Hello, IT.   > $Usr - Hi, I am still ...   \n",
       "0  So my story starts on what was a normal day ta...   \n",
       "\n",
       "                                               title  \\\n",
       "9  How to fix a laptop that won't boot in under a...   \n",
       "8                  OK, now the password is 'D35p41r'   \n",
       "7  [UPDATE]My [26 F] with my husband [29 M] 1 yea...   \n",
       "6  Company-wide email + 30,000 employees + auto-r...   \n",
       "5  I'm pretty sure I knocked a user out from near...   \n",
       "4      Engineer is doing drugs!! No. No they aren't.   \n",
       "3       \"I need you to fix Google Bing immediately!\"   \n",
       "2                   Jack, the Worst End User, Part 4   \n",
       "1              Hi, I am still off sick but I am not.   \n",
       "0  \"Don't bother sending a tech, I'll be dead by ...   \n",
       "\n",
       "                                                 url  \\\n",
       "9  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "8  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "7  https://www.reddit.com/r/relationships/comment...   \n",
       "6  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "5  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "4  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "3  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "2  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "1  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "0  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "\n",
       "                                           sentences  \n",
       "9  [[Last, year, ,, Help, Desk, got, a, call, fro...  \n",
       "8  [[First, post, in, quite, some, time, !], [I, ...  \n",
       "7  [[[, Original, Post, ], (, https, :, //www.red...  \n",
       "6  [[I, witnessed, this, astounding, IT, meltdown...  \n",
       "5  [[I, work, Helpdesk, for, a, retail, store, ch...  \n",
       "4  [[This, just, happened, ...], [So, ,, I, had, ...  \n",
       "3  [[Another, tale, from, the, out, of, hours, IT...  \n",
       "2  [[[, Part, 1, ], (, http, :, //www.reddit.com/...  \n",
       "1  [[>, $, Me, -, Hello, ,, IT, .], [>, $, Usr, -...  \n",
       "0  [[So, my, story, starts, on, what, was, a, nor...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores = redditDF.sort_values('score')[-10:]\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores.index = range(len(redditTopScores) - 1, -1,-1) #Reindex to make things nice in the future\n",
    "redditTopScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can do a depency parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topPostDepParse = list(depParser.parse_sents(redditTopScores['sentences'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a few seconds, but now lets look at the parse tree of one of the sentences\n",
    "\n",
    "The sentence is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So anyway , I get a call from an older gentleman who 's quite bitter and mean right off the bat ( does n't like that I asked for his address / telephone number to verify the account , hates that he has to speak with a machine before reaching an agent , etc . ) .\n"
     ]
    }
   ],
   "source": [
    "targetSentence = 7\n",
    "print(' '.join(redditTopScores['sentences'][0][targetSentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which leads to a very rich dependancy tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"1101pt\" height=\"836pt\"\n",
       " viewBox=\"0.00 0.00 1101.00 836.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 832)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-832 1097,-832 1097,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-806.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-718.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (get)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197,-791.597C197,-779.746 197,-763.817 197,-750.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.5,-750.084 197,-740.084 193.5,-750.084 200.5,-750.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-762.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (So)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.655,-715.979C145.909,-710.834 111.166,-701.379 84,-686 71.5995,-678.98 59.5793,-668.884 49.7996,-659.524\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.0344,-656.81 42.4723,-652.248 47.1022,-661.778 52.0344,-656.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"107\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (anyway)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.92,-704.66C162.066,-699.252 153.786,-692.85 147,-686 139.595,-678.526 132.732,-669.304 127.081,-660.766\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.97,-658.787 121.658,-652.218 124.059,-662.537 129.97,-658.787\"/>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (I)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197,-703.597C197,-691.746 197,-675.817 197,-662.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.5,-662.084 197,-652.084 193.5,-662.084 200.5,-662.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (call)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214.916,-703.993C220.547,-698.411 226.679,-692.078 232,-686 238.975,-678.033 246.144,-668.956 252.403,-660.689\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"255.376,-662.558 258.549,-652.449 249.764,-658.373 255.376,-662.558\"/>\n",
       "<text text-anchor=\"middle\" x=\"257.5\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node7\" class=\"node\"><title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"623\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">34 (number)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;34 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.296,-715.489C293.77,-701.464 478.258,-664.22 569.861,-645.728\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"570.65,-649.139 579.76,-643.729 569.265,-642.277 570.65,-649.139\"/>\n",
       "<text text-anchor=\"middle\" x=\"459.5\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"175\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (a)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.573,-615.597C237.296,-602.807 217.718,-585.268 201.932,-571.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"203.854,-568.15 194.071,-564.084 199.184,-573.363 203.854,-568.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node9\" class=\"node\"><title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">11 (gentleman)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-615.597C271,-603.746 271,-587.817 271,-574.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.5,-574.084 271,-564.084 267.5,-574.084 274.5,-574.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node25\" class=\"node\"><title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">25 (like)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;25 -->\n",
       "<g id=\"edge32\" class=\"edge\"><title>34&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M612.882,-615.597C605.787,-603.394 596.178,-586.867 588.17,-573.093\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"590.985,-570.97 582.933,-564.084 584.933,-574.488 590.985,-570.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"613.5\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node32\" class=\"node\"><title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"672\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">33 (telephone)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;33 -->\n",
       "<g id=\"edge31\" class=\"edge\"><title>34&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M632.916,-615.597C639.869,-603.394 649.285,-586.867 657.133,-573.093\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"660.357,-574.505 662.266,-564.084 654.275,-571.04 660.357,-574.505\"/>\n",
       "<text text-anchor=\"middle\" x=\"682\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node33\" class=\"node\"><title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"793\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">36 (verify)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;36 -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>34&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M666.463,-618.935C682.385,-613.191 700.331,-606.008 716,-598 731.694,-589.979 748.107,-579.443 761.728,-570.031\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"764.073,-572.661 770.24,-564.046 760.047,-566.935 764.073,-572.661\"/>\n",
       "<text text-anchor=\"middle\" x=\"750.5\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">acl</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;8 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.487,-527.935C219.606,-522.502 206.639,-516.268 195,-510 178.987,-501.377 161.82,-490.903 147.353,-481.697\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"149.033,-478.616 138.728,-476.156 145.25,-484.506 149.033,-478.616\"/>\n",
       "<text text-anchor=\"middle\" x=\"207.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (an)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254.608,-527.597C242.673,-514.925 226.346,-497.589 213.091,-483.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"215.495,-480.964 206.091,-476.084 210.399,-485.763 215.495,-480.964\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node12\" class=\"node\"><title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">10 (older)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-527.597C271,-515.746 271,-499.817 271,-486.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.5,-486.084 271,-476.084 267.5,-486.084 274.5,-486.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node13\" class=\"node\"><title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"362\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">15 (bitter)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.415,-527.597C302.948,-514.807 321.507,-497.268 336.471,-483.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"339.059,-485.496 343.923,-476.084 334.251,-480.409 339.059,-485.496\"/>\n",
       "<text text-anchor=\"middle\" x=\"348\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\"><title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">12 (who)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;12 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>15&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M325.685,-443.275C322.421,-442.134 319.158,-441.026 316,-440 287.897,-430.871 279.327,-433.239 252,-422 232.762,-414.088 212.429,-403.12 195.786,-393.382\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.333,-390.23 186.949,-388.126 193.754,-396.246 197.333,-390.23\"/>\n",
       "<text text-anchor=\"middle\" x=\"267.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\"><title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">13 (&#39;s)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;13 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>15&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M334.866,-439.875C326.207,-434.287 316.633,-427.98 308,-422 295.289,-413.195 281.541,-403.145 269.687,-394.308\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271.534,-391.318 261.433,-388.122 267.336,-396.92 271.534,-391.318\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">cop</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\"><title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">14 (quite)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M349.499,-439.658C345.844,-434.165 342.024,-427.967 339,-422 335.156,-414.414 331.667,-405.859 328.758,-397.953\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.02,-396.681 325.4,-388.409 325.417,-399.004 332.02,-396.681\"/>\n",
       "<text text-anchor=\"middle\" x=\"362\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node17\" class=\"node\"><title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"411\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">17 (mean)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M373.849,-439.791C377.553,-434.198 381.566,-427.909 385,-422 389.594,-414.095 394.244,-405.285 398.316,-397.241\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"401.469,-398.763 402.794,-388.251 395.203,-395.642 401.469,-398.763\"/>\n",
       "<text text-anchor=\"middle\" x=\"406.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node18\" class=\"node\"><title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"498\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">16 (and)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M392.99,-439.826C402.691,-434.288 413.374,-428.022 423,-422 437.235,-413.094 452.625,-402.758 465.738,-393.729\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"467.763,-396.584 473.99,-388.012 463.777,-390.829 467.763,-396.584\"/>\n",
       "<text text-anchor=\"middle\" x=\"453.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">cc</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"377\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">18 (right)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M395.706,-351.86C391.632,-346.473 387.636,-340.282 385,-334 381.866,-326.53 379.947,-317.976 378.777,-310.036\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"382.253,-309.627 377.63,-300.094 375.299,-310.43 382.253,-309.627\"/>\n",
       "<text text-anchor=\"middle\" x=\"408\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node20\" class=\"node\"><title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"460\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">21 (bat)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;21 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>17&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.773,-351.914C424.029,-346.218 427.673,-339.837 431,-334 435.641,-325.859 440.691,-316.983 445.258,-308.951\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"448.444,-310.428 450.342,-300.005 442.358,-306.969 448.444,-310.428\"/>\n",
       "<text text-anchor=\"middle\" x=\"456\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node21\" class=\"node\"><title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">19 (off)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;19 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>21&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M452.108,-263.597C446.627,-251.511 439.223,-235.184 433.013,-221.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"436.065,-219.746 428.747,-212.084 429.69,-222.637 436.065,-219.746\"/>\n",
       "<text text-anchor=\"middle\" x=\"456.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node22\" class=\"node\"><title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"499\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">20 (the)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>21&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M467.892,-263.597C473.373,-251.511 480.777,-235.184 486.987,-221.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"490.31,-222.637 491.253,-212.084 483.935,-219.746 490.31,-222.637\"/>\n",
       "<text text-anchor=\"middle\" x=\"492\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node23\" class=\"node\"><title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"492\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">23 (does)</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node24\" class=\"node\"><title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">24 (n&#39;t)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;23 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>25&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M556.608,-527.597C544.673,-514.925 528.346,-497.589 515.091,-483.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"517.495,-480.964 508.091,-476.084 512.399,-485.763 517.495,-480.964\"/>\n",
       "<text text-anchor=\"middle\" x=\"550.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">aux</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>25&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M573,-527.597C573,-515.746 573,-499.817 573,-486.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"576.5,-486.084 573,-476.084 569.5,-486.084 576.5,-486.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"583.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">neg</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\"><title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"657\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">28 (asked)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;28 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>25&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M589.999,-527.597C602.376,-514.925 619.308,-497.589 633.054,-483.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"635.83,-485.683 640.313,-476.084 630.822,-480.792 635.83,-485.683\"/>\n",
       "<text text-anchor=\"middle\" x=\"642\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\"><title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"580\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">26 (that)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;26 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>28&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M640.397,-439.694C635.104,-434.097 629.258,-427.829 624,-422 616.403,-413.577 608.245,-404.215 601.044,-395.835\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"603.641,-393.487 594.481,-388.164 598.322,-398.038 603.641,-393.487\"/>\n",
       "<text text-anchor=\"middle\" x=\"638.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\"><title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"657\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">27 (I)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;27 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>28&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M657,-439.597C657,-427.746 657,-411.817 657,-398.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"660.5,-398.084 657,-388.084 653.5,-398.084 660.5,-398.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"672.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node29\" class=\"node\"><title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"745\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">31 (address)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;31 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>28&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M674.808,-439.597C687.895,-426.807 705.842,-409.268 720.313,-395.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"722.813,-397.577 727.519,-388.084 717.921,-392.57 722.813,-397.577\"/>\n",
       "<text text-anchor=\"middle\" x=\"724\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\"><title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"676\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">29 (for)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M731.037,-351.597C720.964,-339.042 707.218,-321.91 695.984,-307.908\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"698.695,-305.694 689.707,-300.084 693.235,-310.074 698.695,-305.694\"/>\n",
       "<text text-anchor=\"middle\" x=\"728.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\"><title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"754\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">30 (his)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M746.821,-351.597C748.061,-339.746 749.728,-323.817 751.144,-310.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"754.652,-310.394 752.212,-300.084 747.69,-309.665 754.652,-310.394\"/>\n",
       "<text text-anchor=\"middle\" x=\"780.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node34\" class=\"node\"><title>35</title>\n",
       "<text text-anchor=\"middle\" x=\"793\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">35 (to)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;35 -->\n",
       "<g id=\"edge33\" class=\"edge\"><title>36&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M793,-527.597C793,-515.746 793,-499.817 793,-486.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"796.5,-486.084 793,-476.084 789.5,-486.084 796.5,-486.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"807.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 38 -->\n",
       "<g id=\"node35\" class=\"node\"><title>38</title>\n",
       "<text text-anchor=\"middle\" x=\"890\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">38 (account)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;38 -->\n",
       "<g id=\"edge34\" class=\"edge\"><title>36&#45;&gt;38</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M812.629,-527.597C827.187,-514.69 847.201,-496.946 863.226,-482.738\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"865.57,-485.337 870.731,-476.084 860.926,-480.099 865.57,-485.337\"/>\n",
       "<text text-anchor=\"middle\" x=\"862.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node36\" class=\"node\"><title>37</title>\n",
       "<text text-anchor=\"middle\" x=\"836\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">37 (the)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;37 -->\n",
       "<g id=\"edge37\" class=\"edge\"><title>38&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M879.072,-439.597C871.336,-427.277 860.833,-410.549 852.135,-396.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"855.009,-394.692 846.727,-388.084 849.081,-398.414 855.009,-394.692\"/>\n",
       "<text text-anchor=\"middle\" x=\"876\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node37\" class=\"node\"><title>40</title>\n",
       "<text text-anchor=\"middle\" x=\"920\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">40 (hates)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;40 -->\n",
       "<g id=\"edge35\" class=\"edge\"><title>38&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M896.071,-439.597C900.246,-427.629 905.872,-411.501 910.62,-397.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"914.051,-398.679 914.04,-388.084 907.442,-396.373 914.051,-398.679\"/>\n",
       "<text text-anchor=\"middle\" x=\"919.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 54 -->\n",
       "<g id=\"node38\" class=\"node\"><title>54</title>\n",
       "<text text-anchor=\"middle\" x=\"1004\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">54 (etc)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;54 -->\n",
       "<g id=\"edge36\" class=\"edge\"><title>38&#45;&gt;54</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M912.796,-439.803C930.115,-426.737 954.121,-408.628 973.157,-394.267\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"975.369,-396.983 981.244,-388.167 971.153,-391.395 975.369,-396.983\"/>\n",
       "<text text-anchor=\"middle\" x=\"969.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 43 -->\n",
       "<g id=\"node39\" class=\"node\"><title>43</title>\n",
       "<text text-anchor=\"middle\" x=\"842\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">43 (has)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;43 -->\n",
       "<g id=\"edge38\" class=\"edge\"><title>40&#45;&gt;43</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M904.216,-351.597C892.722,-338.925 877,-321.589 864.236,-307.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"866.806,-305.14 857.495,-300.084 861.62,-309.843 866.806,-305.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"906\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g id=\"node40\" class=\"node\"><title>50</title>\n",
       "<text text-anchor=\"middle\" x=\"961\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">50 (reaching)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;50 -->\n",
       "<g id=\"edge39\" class=\"edge\"><title>40&#45;&gt;50</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M928.297,-351.597C934.059,-339.511 941.842,-323.184 948.371,-309.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"951.711,-310.617 952.855,-300.084 945.392,-307.604 951.711,-310.617\"/>\n",
       "<text text-anchor=\"middle\" x=\"959.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">advcl</text>\n",
       "</g>\n",
       "<!-- 41 -->\n",
       "<g id=\"node41\" class=\"node\"><title>41</title>\n",
       "<text text-anchor=\"middle\" x=\"703\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">41 (that)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;41 -->\n",
       "<g id=\"edge41\" class=\"edge\"><title>43&#45;&gt;41</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M810.711,-266.787C798.389,-260.824 784.278,-253.529 772,-246 758.381,-237.648 744.062,-227.343 732.021,-218.187\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"734.142,-215.403 724.085,-212.07 729.868,-220.947 734.142,-215.403\"/>\n",
       "<text text-anchor=\"middle\" x=\"786.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 42 -->\n",
       "<g id=\"node42\" class=\"node\"><title>42</title>\n",
       "<text text-anchor=\"middle\" x=\"782\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">42 (he)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;42 -->\n",
       "<g id=\"edge40\" class=\"edge\"><title>43&#45;&gt;42</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M828.863,-263.681C824.69,-258.082 820.096,-251.818 816,-246 810.241,-237.821 804.128,-228.772 798.696,-220.595\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"801.549,-218.564 793.119,-212.147 795.707,-222.421 801.549,-218.564\"/>\n",
       "<text text-anchor=\"middle\" x=\"831.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 45 -->\n",
       "<g id=\"node43\" class=\"node\"><title>45</title>\n",
       "<text text-anchor=\"middle\" x=\"866\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">45 (speak)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;45 -->\n",
       "<g id=\"edge42\" class=\"edge\"><title>43&#45;&gt;45</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M846.857,-263.597C850.197,-251.629 854.697,-235.501 858.496,-221.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"861.915,-222.657 861.232,-212.084 855.173,-220.775 861.915,-222.657\"/>\n",
       "<text text-anchor=\"middle\" x=\"875.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">xcomp</text>\n",
       "</g>\n",
       "<!-- 49 -->\n",
       "<g id=\"node48\" class=\"node\"><title>49</title>\n",
       "<text text-anchor=\"middle\" x=\"961\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">49 (before)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;49 -->\n",
       "<g id=\"edge47\" class=\"edge\"><title>50&#45;&gt;49</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M961,-263.597C961,-251.746 961,-235.817 961,-222.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"964.5,-222.084 961,-212.084 957.5,-222.084 964.5,-222.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"975.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node49\" class=\"node\"><title>52</title>\n",
       "<text text-anchor=\"middle\" x=\"1056\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">52 (agent)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;52 -->\n",
       "<g id=\"edge48\" class=\"edge\"><title>50&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M980.225,-263.597C994.353,-250.807 1013.73,-233.268 1029.35,-219.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1032.06,-221.39 1037.13,-212.084 1027.37,-216.2 1032.06,-221.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"1029.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 44 -->\n",
       "<g id=\"node44\" class=\"node\"><title>44</title>\n",
       "<text text-anchor=\"middle\" x=\"840\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">44 (to)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;44 -->\n",
       "<g id=\"edge43\" class=\"edge\"><title>45&#45;&gt;44</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M860.739,-175.597C857.12,-163.629 852.245,-147.501 848.13,-133.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"851.409,-132.643 845.165,-124.084 844.709,-134.669 851.409,-132.643\"/>\n",
       "<text text-anchor=\"middle\" x=\"869.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 48 -->\n",
       "<g id=\"node45\" class=\"node\"><title>48</title>\n",
       "<text text-anchor=\"middle\" x=\"931\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">48 (machine)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;48 -->\n",
       "<g id=\"edge44\" class=\"edge\"><title>45&#45;&gt;48</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M879.154,-175.597C888.554,-163.159 901.35,-146.23 911.877,-132.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"914.85,-134.172 918.088,-124.084 909.266,-129.951 914.85,-134.172\"/>\n",
       "<text text-anchor=\"middle\" x=\"920\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node46\" class=\"node\"><title>46</title>\n",
       "<text text-anchor=\"middle\" x=\"891\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">46 (with)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;46 -->\n",
       "<g id=\"edge46\" class=\"edge\"><title>48&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M922.905,-87.5966C917.284,-75.5112 909.69,-59.1844 903.321,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"906.337,-43.6751 898.946,-36.084 899.99,-46.6273 906.337,-43.6751\"/>\n",
       "<text text-anchor=\"middle\" x=\"926.5\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 47 -->\n",
       "<g id=\"node47\" class=\"node\"><title>47</title>\n",
       "<text text-anchor=\"middle\" x=\"970\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">47 (a)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;47 -->\n",
       "<g id=\"edge45\" class=\"edge\"><title>48&#45;&gt;47</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M938.892,-87.5966C944.373,-75.5112 951.777,-59.1844 957.987,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"961.31,-46.6368 962.253,-36.084 954.935,-43.7458 961.31,-46.6368\"/>\n",
       "<text text-anchor=\"middle\" x=\"962\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node50\" class=\"node\"><title>51</title>\n",
       "<text text-anchor=\"middle\" x=\"1056\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">51 (an)</text>\n",
       "</g>\n",
       "<!-- 52&#45;&gt;51 -->\n",
       "<g id=\"edge49\" class=\"edge\"><title>52&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1056,-175.597C1056,-163.746 1056,-147.817 1056,-134.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1059.5,-134.084 1056,-124.084 1052.5,-134.084 1059.5,-134.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"1065\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1121b8748>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(list(topPostDepParse[targetSentence])[0].to_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run NER over our entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redditTopScores['classified_sents'] = redditTopScores['sentences'].apply(lambda x: nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, O), (year, O), (,, O), (Help, O), (De...\n",
       "8    [[(First, O), (post, O), (in, O), (quite, O), ...\n",
       "7    [[([, O), (Original, O), (Post, O), (], O), ((...\n",
       "6    [[(I, O), (witnessed, O), (this, O), (astoundi...\n",
       "5    [[(I, O), (work, O), (Helpdesk, ORGANIZATION),...\n",
       "4    [[(This, O), (just, O), (happened, O), (..., O...\n",
       "3    [[(Another, O), (tale, O), (from, O), (the, O)...\n",
       "2    [[([, O), (Part, O), (1, O), (], O), ((, O), (...\n",
       "1    [[(>, O), ($, O), (Me, O), (-, O), (Hello, O),...\n",
       "0    [[(So, O), (my, O), (story, O), (starts, O), (...\n",
       "Name: classified_sents, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['classified_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 401),\n",
       " ('I', 245),\n",
       " ('the', 226),\n",
       " (',', 205),\n",
       " ('to', 197),\n",
       " ('a', 143),\n",
       " ('and', 135),\n",
       " ('>', 106),\n",
       " ('you', 102),\n",
       " ('of', 97)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if ent in entityCounts:\n",
    "                entityCounts[ent] += 1\n",
    "            else:\n",
    "                entityCounts[ent] = 1\n",
    "sortedEntities = sorted(entityCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedEntities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the most common non-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jack', 17),\n",
       " ('Google', 6),\n",
       " ('Smith', 5),\n",
       " ('Steve', 2),\n",
       " ('CMD', 1),\n",
       " ('Citrix', 1),\n",
       " ('GOOGLE', 1),\n",
       " ('Spotify', 1),\n",
       " ('Helpdesk', 1),\n",
       " ('UK', 1)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonObjCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind == 'O':\n",
    "                continue\n",
    "            elif ent in nonObjCounts:\n",
    "                nonObjCounts[ent] += 1\n",
    "            else:\n",
    "                nonObjCounts[ent] = 1\n",
    "sortedNonObj = sorted(nonObjCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedNonObj[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These have much smaller counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, JJ), (year, NN), (,, ,), (Help, NN), ...\n",
       "8    [[(First, JJ), (post, NN), (in, IN), (quite, R...\n",
       "7    [[([, NNP), (Original, NNP), (Post, NNP), (], ...\n",
       "6    [[(I, PRP), (witnessed, VBD), (this, DT), (ast...\n",
       "5    [[(I, PRP), (work, VBP), (Helpdesk, NNP), (for...\n",
       "4    [[(This, DT), (just, RB), (happened, VBN), (.....\n",
       "3    [[(Another, DT), (tale, NN), (from, IN), (the,...\n",
       "2    [[([, NNP), (Part, NNP), (1, CD), (], FW), ((,...\n",
       "1    [[(>, JJR), ($, $), (Me, PRP), (-, :), (Hello,...\n",
       "0    [[(So, RB), (my, PRP$), (story, NN), (starts, ...\n",
       "Name: POS_sents, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And count the number of `NN` (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('password', 21),\n",
       " ('(', 19),\n",
       " (')', 14),\n",
       " ('time', 14),\n",
       " ('computer', 12),\n",
       " ('lot', 12),\n",
       " ('life', 11),\n",
       " ('email', 11),\n",
       " ('**Genius**', 10),\n",
       " ('message', 9)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the top nouns are not the same as the top entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also look for subject, object, target triples in one of the stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "Adding annotator tokenize\n",
      "Adding annotator ssplit\n",
      "Adding annotator pos\n",
      "Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.6 sec].\n",
      "Adding annotator lemma\n",
      "Adding annotator depparse\n",
      "Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "PreComputed 99996, Elapsed Time: 12.38 (s)\n",
      "Initializing dependency parser ... done [13.7 sec].\n",
      "Adding annotator natlog\n",
      "Adding annotator openie\n",
      "Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0887 seconds]\n",
      "Processing file: /var/folders/lk/cq97m8gs5_z62sdfszp2x9jw0000gn/T/tmpikia6d3v\n",
      "All files have been queued; awaiting termination...\n",
      "DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ieDF = openIE(redditTopScores['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll get</td>\n",
       "      <td>calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>Quite often 'll get</td>\n",
       "      <td>calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>often 'll get</td>\n",
       "      <td>calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.831036</td>\n",
       "      <td>we</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>straight analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>straight analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>would supply analog cable to</td>\n",
       "      <td>homes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.831036</td>\n",
       "      <td>we</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.831036</td>\n",
       "      <td>we</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>straight analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>straight analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.831036</td>\n",
       "      <td>we</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>would supply analog cable to</td>\n",
       "      <td>many homes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>our equipment</td>\n",
       "      <td>receive</td>\n",
       "      <td>channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>our digital equipment</td>\n",
       "      <td>receive</td>\n",
       "      <td>channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>repeat offenders</td>\n",
       "      <td>is with</td>\n",
       "      <td>long ticket histories of types of issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>I</td>\n",
       "      <td>anyway get</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>I</td>\n",
       "      <td>get</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>he</td>\n",
       "      <td>speak with</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>I</td>\n",
       "      <td>So anyway get</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>he</td>\n",
       "      <td>has</td>\n",
       "      <td>speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>he</td>\n",
       "      <td>has</td>\n",
       "      <td>speak with machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>call</td>\n",
       "      <td>however was going</td>\n",
       "      <td>little different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>call</td>\n",
       "      <td>was going</td>\n",
       "      <td>little different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.780294</td>\n",
       "      <td>handling</td>\n",
       "      <td>types of</td>\n",
       "      <td>customers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>call</td>\n",
       "      <td>was going</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>made</td>\n",
       "      <td>man happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>made</td>\n",
       "      <td>man happy again for once in long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>really made</td>\n",
       "      <td>old man happy for once in time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>happy for</td>\n",
       "      <td>once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>old man</td>\n",
       "      <td>happy again for</td>\n",
       "      <td>once in time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>happy again for</td>\n",
       "      <td>once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>really made</td>\n",
       "      <td>old man happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>old man</td>\n",
       "      <td>happy again for</td>\n",
       "      <td>once in very long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>really made</td>\n",
       "      <td>man happy again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>happy for</td>\n",
       "      <td>once in long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>made</td>\n",
       "      <td>old man happy again for once in time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>made</td>\n",
       "      <td>man happy again for once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>really made</td>\n",
       "      <td>old man happy again for once in very long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>really made</td>\n",
       "      <td>old man happy again for once in long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>old man</td>\n",
       "      <td>happy for</td>\n",
       "      <td>once in time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>really made</td>\n",
       "      <td>man happy for once in time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>made</td>\n",
       "      <td>man happy for once in very long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>made</td>\n",
       "      <td>old man happy for once in very long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>really made</td>\n",
       "      <td>man happy again for once in long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>made</td>\n",
       "      <td>man happy again for once in very long time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>letter</td>\n",
       "      <td>put on</td>\n",
       "      <td>our front entrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>letter</td>\n",
       "      <td>put to</td>\n",
       "      <td>retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>letter</td>\n",
       "      <td>put on</td>\n",
       "      <td>our entrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>letter</td>\n",
       "      <td>was</td>\n",
       "      <td>framed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>they</td>\n",
       "      <td>going through</td>\n",
       "      <td>lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>they</td>\n",
       "      <td>just going through</td>\n",
       "      <td>lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>I</td>\n",
       "      <td>still think about</td>\n",
       "      <td>Mr. Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>I</td>\n",
       "      <td>still think occasionally about</td>\n",
       "      <td>Mr. Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>I</td>\n",
       "      <td>think occasionally about</td>\n",
       "      <td>Mr. Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>I</td>\n",
       "      <td>think about</td>\n",
       "      <td>Mr. Smith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     certainty                subject                            verb  \\\n",
       "0     1.000000                     we                         'll get   \n",
       "1     1.000000                     we             Quite often 'll get   \n",
       "2     1.000000                     we                   often 'll get   \n",
       "3     0.831036                     we                            coax   \n",
       "4     0.774359  straight analog cable                            coax   \n",
       "5     0.774359           analog cable                            coax   \n",
       "6     0.774359  straight analog cable                            coax   \n",
       "7     1.000000                     we    would supply analog cable to   \n",
       "8     0.831036                     we                            coax   \n",
       "9     0.774359           analog cable                            coax   \n",
       "10    0.831036                     we                            coax   \n",
       "11    0.774359  straight analog cable                            coax   \n",
       "12    0.774359  straight analog cable                            coax   \n",
       "13    0.831036                     we                            coax   \n",
       "14    0.774359           analog cable                            coax   \n",
       "15    1.000000                     we    would supply analog cable to   \n",
       "16    0.774359           analog cable                            coax   \n",
       "17    1.000000          our equipment                         receive   \n",
       "18    1.000000  our digital equipment                         receive   \n",
       "19    1.000000       repeat offenders                         is with   \n",
       "20    1.000000                      I                      anyway get   \n",
       "21    1.000000                      I                             get   \n",
       "22    1.000000                     he                      speak with   \n",
       "23    1.000000                      I                   So anyway get   \n",
       "24    1.000000                     he                             has   \n",
       "25    1.000000                     he                             has   \n",
       "26    1.000000                   call               however was going   \n",
       "27    1.000000                   call                       was going   \n",
       "28    0.780294               handling                        types of   \n",
       "29    1.000000                   call                       was going   \n",
       "..         ...                    ...                             ...   \n",
       "161   1.000000                     it                            made   \n",
       "162   1.000000                     it                            made   \n",
       "163   1.000000                     it                     really made   \n",
       "164   1.000000                    man                       happy for   \n",
       "165   1.000000                old man                 happy again for   \n",
       "166   1.000000                    man                 happy again for   \n",
       "167   1.000000                     it                     really made   \n",
       "168   1.000000                old man                 happy again for   \n",
       "169   1.000000                     it                     really made   \n",
       "170   1.000000                    man                       happy for   \n",
       "171   1.000000                     it                            made   \n",
       "172   1.000000                     it                            made   \n",
       "173   1.000000                     it                     really made   \n",
       "174   1.000000                     it                     really made   \n",
       "175   1.000000                old man                       happy for   \n",
       "176   1.000000                     it                     really made   \n",
       "177   1.000000                     it                            made   \n",
       "178   1.000000                     it                            made   \n",
       "179   1.000000                     it                     really made   \n",
       "180   1.000000                     it                            made   \n",
       "181   1.000000                 letter                          put on   \n",
       "182   1.000000                 letter                          put to   \n",
       "183   1.000000                 letter                          put on   \n",
       "184   1.000000                 letter                             was   \n",
       "185   1.000000                   they                   going through   \n",
       "186   1.000000                   they              just going through   \n",
       "187   1.000000                      I               still think about   \n",
       "188   1.000000                      I  still think occasionally about   \n",
       "189   1.000000                      I        think occasionally about   \n",
       "190   1.000000                      I                     think about   \n",
       "\n",
       "                                             object  \n",
       "0                                             calls  \n",
       "1                                             calls  \n",
       "2                                             calls  \n",
       "3                                      direct to TV  \n",
       "4                                  direct from wall  \n",
       "5                            direct from wall to TV  \n",
       "6                                      direct to TV  \n",
       "7                                             homes  \n",
       "8                                  direct from wall  \n",
       "9                                  direct from wall  \n",
       "10                           direct from wall to TV  \n",
       "11                           direct from wall to TV  \n",
       "12                                           direct  \n",
       "13                                           direct  \n",
       "14                                     direct to TV  \n",
       "15                                       many homes  \n",
       "16                                           direct  \n",
       "17                                         channels  \n",
       "18                                         channels  \n",
       "19         long ticket histories of types of issues  \n",
       "20                                             call  \n",
       "21                                             call  \n",
       "22                                          machine  \n",
       "23                                             call  \n",
       "24                                            speak  \n",
       "25                               speak with machine  \n",
       "26                                 little different  \n",
       "27                                 little different  \n",
       "28                                        customers  \n",
       "29                                        different  \n",
       "..                                              ...  \n",
       "161                                       man happy  \n",
       "162           man happy again for once in long time  \n",
       "163                  old man happy for once in time  \n",
       "164                                            once  \n",
       "165                                    once in time  \n",
       "166                                            once  \n",
       "167                                   old man happy  \n",
       "168                          once in very long time  \n",
       "169                                 man happy again  \n",
       "170                               once in long time  \n",
       "171            old man happy again for once in time  \n",
       "172                        man happy again for once  \n",
       "173  old man happy again for once in very long time  \n",
       "174       old man happy again for once in long time  \n",
       "175                                    once in time  \n",
       "176                      man happy for once in time  \n",
       "177            man happy for once in very long time  \n",
       "178        old man happy for once in very long time  \n",
       "179           man happy again for once in long time  \n",
       "180      man happy again for once in very long time  \n",
       "181                              our front entrance  \n",
       "182                                          retail  \n",
       "183                                    our entrance  \n",
       "184                                          framed  \n",
       "185                                             lot  \n",
       "186                                             lot  \n",
       "187                                       Mr. Smith  \n",
       "188                                       Mr. Smith  \n",
       "189                                       Mr. Smith  \n",
       "190                                       Mr. Smith  \n",
       "\n",
       "[191 rows x 4 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost 200 triples in only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(redditTopScores['sentences'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentences and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(s) for s in redditTopScores['sentences'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find at the most common subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I                        48\n",
       "it                       42\n",
       "he                       19\n",
       "He                       18\n",
       "we                       11\n",
       "old man                   8\n",
       "man                       8\n",
       "straight analog cable     4\n",
       "analog cable              4\n",
       "our booking calendar      4\n",
       "call                      4\n",
       "letter                    4\n",
       "my supervisor             3\n",
       "his TV set                2\n",
       "you                       2\n",
       "they                      2\n",
       "TV                        2\n",
       "handling                  1\n",
       "our equipment             1\n",
       "our digital equipment     1\n",
       "people                    1\n",
       "repeat offenders          1\n",
       "me                        1\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'I' occures most often with the following verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "could come                        8\n",
       "even brought                      5\n",
       "brought                           5\n",
       "was                               4\n",
       "had                               4\n",
       "speak for                         3\n",
       "'ve dealt with                    1\n",
       "eventually had                    1\n",
       "ask                               1\n",
       "think about                       1\n",
       "took                              1\n",
       "complaint in                      1\n",
       "have                              1\n",
       "instantly felt                    1\n",
       "get to                            1\n",
       "still think occasionally about    1\n",
       "get                               1\n",
       "speak with                        1\n",
       "do                                1\n",
       "So anyway get                     1\n",
       "think occasionally about          1\n",
       "felt                              1\n",
       "still think about                 1\n",
       "anyway get                        1\n",
       "had cable within                  1\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr. Smith                                             4\n",
       "call                                                  3\n",
       "him                                                   3\n",
       "remote                                                2\n",
       "bad                                                   2\n",
       "simplified remote for his set top box                 2\n",
       "this                                                  2\n",
       "get                                                   2\n",
       "willing                                               2\n",
       "simplified remote                                     2\n",
       "remote for his set top box                            2\n",
       "bit                                                   1\n",
       "book                                                  1\n",
       "residence                                             1\n",
       "her                                                   1\n",
       "speak for bit                                         1\n",
       "speak for bit about account                           1\n",
       "bit about account for Mr. Smith                       1\n",
       "cable running                                         1\n",
       "how useless                                           1\n",
       "speak with her for bit about account                  1\n",
       "bit about account                                     1\n",
       "speak for bit about account for Mr. Smith             1\n",
       "speak                                                 1\n",
       "cable                                                 1\n",
       "cable running again                                   1\n",
       "it                                                    1\n",
       "30 seconds                                            1\n",
       "experience                                            1\n",
       "speak with her for bit about account for Mr. Smith    1\n",
       "speak with her for bit                                1\n",
       "useless                                               1\n",
       "speak with her                                        1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
