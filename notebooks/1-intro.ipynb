{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout\n",
    "\n",
    "+ opening\n",
    "    + contents\n",
    "    + files used\n",
    "    + packages used\n",
    "\n",
    "+ Scraping\n",
    "    + Images\n",
    "        + OCR\n",
    "    + raw text\n",
    "    + html\n",
    "    + PDFs\n",
    "    + word doc etc.\n",
    "+ spidering\n",
    "    + wikipedia\n",
    "    + APIs\n",
    "        + REST\n",
    "        + tumblr\n",
    "+ reading files\n",
    "    + encodings\n",
    "    + unicode\n",
    "+ filtering\n",
    "+ data structures\n",
    "    + pandas\n",
    "\n",
    "\n",
    "# Week 1 - Intro\n",
    "\n",
    "Intro stuff ...\n",
    "\n",
    "For this notebook we will be using the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests #http requests\n",
    "import bs4 #called 'BeautifulSoup', a html parser\n",
    "import re #for regexs\n",
    "import pandas #DataFrames\n",
    "import urllib.parse #For joining urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be working on the following files/urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "example_text_file = 'sometextfile.txt'\n",
    "information_extraction_pdf = 'https://web.stanford.edu/~jurafsky/slp3/20.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "Before we can start analyzing content we need to obtain it. Sometimes it will be provided to us before hand, but often we will need to download it. As a starting example we will attempt to download the wikipedia page on content analysis. The page is located at [https://en.wikipedia.org/wiki/Content_analysis](https://en.wikipedia.org/wiki/Content_analysis) so lets start with that.\n",
    "\n",
    "We can do this by making an HTTP GET request to that url, a GET request is simply a request to the server to provide the contents given by some url. The other request we will be using in this class is called a POST request and requests the server to take some content we provide. While the Python standard library does have the ability do make GET requests we will be using the [_requests_](http://docs.python-requests.org/en/master/) package as it is _'the only Non-GMO HTTP library for Python'_, also it provides a nicer interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "requests.get('https://en.wikipedia.org/wiki/Content_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Response [200]'` means the server responded with what we asked for. If you get another number (e.g. 404) it likely means there was some kind of error, these codes are called HTTP response codes and a list of them can be found [here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). The response object contains all the data the server sent including the website's contents and the HTTP header. We are interested in the contents which we can access with the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Content analysis - Wikipedia</title>\n",
      "<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n",
      "<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Content_analysis\",\"wgTitle\":\"Content analysis\",\"wgCurRevisionId\":735443188,\"wgRevisionId\":735443188,\"wgArticleId\":473317,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles needing cleanup from April 2008\",\"All articles needing cleanup\",\"Cleanup tagged articles without a reason field from April 2008\",\"Wikipedia pages needing cleanup from April 2008\",\"Articles needing expert attention with no reason or talk parameter\",\"Articles needing expert attention from April 2008\",\"All artic\n"
     ]
    }
   ],
   "source": [
    "wikiContentRequest = requests.get('https://en.wikipedia.org/wiki/Content_analysis')\n",
    "print(wikiContentRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we were looking for, because it is the start of the HTML that makes up the website. This is HTML and is meant to be read by computers. Luckily we have a computer to parse it for us. To do the parsing we will use [_Beautiful Soup_](https://www.crummy.com/software/BeautifulSoup/) which is a better parser than the one in the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis - Wikipedia\n",
      "document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );\n",
      "(window.RLQ=window.RLQ||[]).push(functio\n"
     ]
    }
   ],
   "source": [
    "wikiContentSoup = bs4.BeautifulSoup(wikiContentRequest.text, 'html.parser')\n",
    "print(wikiContentSoup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better but there's a bunch of random whitespace and we have way more than just the text of the article. This is because what we requested is the whole webpage, not just the text for the article.\n",
    "\n",
    "We need to extract only the text we care about, in order to do this we will need to inspect the html. One way to do this is to simply go to the website with a browser and use its inspection or view source tool, but if there is javascript or other dynamic loading occurring on the page it is very likely that what Python receives is not what you will see. So we will need to view what Python receives. To do this we can save the html `requests` obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "\n",
    "with open(content_analysis_save, mode='w', encoding='utf-8') as f:\n",
    "    f.write(wikiContentRequest.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets open the file (`wikipedia_content_analysis.html`) we just created with a web browser. It should look sort of like the original but missing all the images and formatting.\n",
    "\n",
    "As there is very little standardization on structuring webpages figuring out how best to extract what you want is an art. Looking at this page it looks like all the main textual content is within `<p>`(paragraph) tags inside the `<body>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content analysis is \"a wide and heterogeneous set of manual or computer-assisted techniques for contextualized interpretations of documents produced by communication processes in the strict sense of that phrase (any kind of text, written, iconic, multimedia, etc.) or signification processes (traces and artifacts), having as ultimate goal the production of valid and trustworthy inferences.\"\n",
      "Content analysis has come to be a sort of 'umbrella term' referring to an almost boundless set of quite diverse research approaches and techniques. Broadly, it can refer to methods for studying and/or retrieving meaningful information from documents.[1] In a more focused way, content analysis refers to a family of techniques for studying the \"mute evidence\" of texts and artifacts.[2] There are 5 types of texts in content analysis:\n",
      "Content analysis can also be described as studying traces, which are documents from past times, and artifacts, which are non-linguistic documents. Texts are understood to be produced by communication processes in a broad sense of that phrase - often gaining mean through abduction.[1][3]\n"
     ]
    }
   ],
   "source": [
    "contentPTags = wikiContentSoup.body.findAll('p')\n",
    "for pTag in contentPTags[:3]:\n",
    "    print(pTag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the text from the page, split up by paragraph. If we wanted to get the section headers or references as well it would require a bit more work, but is doable.\n",
    "\n",
    "There is one more thing we might want to do before sending this text to be processed, remove the references indicators (`[2]`, `[3]` , etc). To do this we can use a short regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       paragraph-text\n",
      "0   Content analysis is \"a wide and heterogeneous ...\n",
      "1   Content analysis has come to be a sort of 'umb...\n",
      "2   Content analysis can also be described as stud...\n",
      "3   Despite the wide variety of options, generally...\n",
      "4   Over the years, content analysis has been appl...\n",
      "5   In recent times, particularly with the advent ...\n",
      "6   Quantitative content analysis has enjoyed a re...\n",
      "7                                                    \n",
      "8                                                    \n",
      "9   The method of content analysis enables the res...\n",
      "10  Since the 1980s, content analysis has become a...\n",
      "11  The creation of coding frames is intrinsically...\n",
      "12  Mimetic Convergence thus aims to show the proc...\n",
      "13  Every content analysis should depart from a hy...\n",
      "14  As an evaluation approach, content analysis is...\n",
      "15  Qualitative content analysis is “a systematic,...\n",
      "16  Holsti groups fifteen uses of content analysis...\n",
      "17  He also places these uses into the context of ...\n",
      "18  The following table shows fifteen uses of cont...\n",
      "19  According to Dr. Klaus Krippendorff, six quest...\n",
      "20  The assumption is that words and phrases menti...\n",
      "21  Qualitatively, content analysis can involve an...\n",
      "22  Normally, content analysis can only be applied...\n",
      "23  A further step in analysis is the distinction ...\n",
      "24  Dermot McKeone highlighted the difference betw...\n",
      "25  As the uncritical use of text is today widely ...\n",
      "26  Neuendorf suggests that when human coders are ...\n"
     ]
    }
   ],
   "source": [
    "contentParagraphs = []\n",
    "for pTag in contentPTags:\n",
    "    contentParagraphs.append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "\n",
    "#convert to a DataFrame\n",
    "contentParagraphsDF = pandas.DataFrame({'paragraph-text' : contentParagraphs})\n",
    "print(contentParagraphsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `DataFrame` of all the relevant text from the page ready to be processed\n",
    "\n",
    "# Spidering\n",
    "\n",
    "What if we want to to get a bunch of different pages from wikipedia. We would need to get the url of each of the pages we want, usually we will want pages that are linked to by other pages, so we will need to parse pages and find the links. Right now we will be getting all the links in the body of the content analysis page.\n",
    "\n",
    "To do this we will need to find all the `<a>` (anchor) tags with `href`s inside of `<p>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/wiki/Text_(literary_theory)\" title=\"Text (literary theory)\">texts</a>, <a href=\"/wiki/Trace_evidence\" title=\"Trace evidence\">traces</a>, <a href=\"/wiki/Abductive_reasoning\" title=\"Abductive reasoning\">abduction</a>, <a href=\"/wiki/Hermeneutics\" title=\"Hermeneutics\">Hermeneutics</a>]\n"
     ]
    }
   ],
   "source": [
    "tagLinks = []\n",
    "for pTag in contentPTags:\n",
    "    #we only want hrefs that link to wiki pages\n",
    "    tagLinks += pTag.findAll('a', href=re.compile('/wiki/'), class_=False)\n",
    "print(tagLinks[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be adding these new texts to our DataFrame `contentParagraphsDF` so we will need to add 2 more columns to keep track of paragraph numbers and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>paragraph-number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Content analysis is \"a wide and heterogeneous ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Content analysis has come to be a sort of 'umb...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despite the wide variety of options, generally...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The method of content analysis enables the res...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Since the 1980s, content analysis has become a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The creation of coding frames is intrinsically...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mimetic Convergence thus aims to show the proc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Every content analysis should depart from a hy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>As an evaluation approach, content analysis is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qualitative content analysis is “a systematic,...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>According to Dr. Klaus Krippendorff, six quest...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The assumption is that words and phrases menti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Qualitatively, content analysis can involve an...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Normally, content analysis can only be applied...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dermot McKeone highlighted the difference betw...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>As the uncritical use of text is today widely ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Neuendorf suggests that when human coders are ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paragraph-text  \\\n",
       "0   Content analysis is \"a wide and heterogeneous ...   \n",
       "1   Content analysis has come to be a sort of 'umb...   \n",
       "2   Content analysis can also be described as stud...   \n",
       "3   Despite the wide variety of options, generally...   \n",
       "4   Over the years, content analysis has been appl...   \n",
       "5   In recent times, particularly with the advent ...   \n",
       "6   Quantitative content analysis has enjoyed a re...   \n",
       "7                                                       \n",
       "8                                                       \n",
       "9   The method of content analysis enables the res...   \n",
       "10  Since the 1980s, content analysis has become a...   \n",
       "11  The creation of coding frames is intrinsically...   \n",
       "12  Mimetic Convergence thus aims to show the proc...   \n",
       "13  Every content analysis should depart from a hy...   \n",
       "14  As an evaluation approach, content analysis is...   \n",
       "15  Qualitative content analysis is “a systematic,...   \n",
       "16  Holsti groups fifteen uses of content analysis...   \n",
       "17  He also places these uses into the context of ...   \n",
       "18  The following table shows fifteen uses of cont...   \n",
       "19  According to Dr. Klaus Krippendorff, six quest...   \n",
       "20  The assumption is that words and phrases menti...   \n",
       "21  Qualitatively, content analysis can involve an...   \n",
       "22  Normally, content analysis can only be applied...   \n",
       "23  A further step in analysis is the distinction ...   \n",
       "24  Dermot McKeone highlighted the difference betw...   \n",
       "25  As the uncritical use of text is today widely ...   \n",
       "26  Neuendorf suggests that when human coders are ...   \n",
       "\n",
       "                                            source  paragraph-number  \n",
       "0   https://en.wikipedia.org/wiki/Content_analysis                 0  \n",
       "1   https://en.wikipedia.org/wiki/Content_analysis                 1  \n",
       "2   https://en.wikipedia.org/wiki/Content_analysis                 2  \n",
       "3   https://en.wikipedia.org/wiki/Content_analysis                 3  \n",
       "4   https://en.wikipedia.org/wiki/Content_analysis                 4  \n",
       "5   https://en.wikipedia.org/wiki/Content_analysis                 5  \n",
       "6   https://en.wikipedia.org/wiki/Content_analysis                 6  \n",
       "7   https://en.wikipedia.org/wiki/Content_analysis                 7  \n",
       "8   https://en.wikipedia.org/wiki/Content_analysis                 8  \n",
       "9   https://en.wikipedia.org/wiki/Content_analysis                 9  \n",
       "10  https://en.wikipedia.org/wiki/Content_analysis                10  \n",
       "11  https://en.wikipedia.org/wiki/Content_analysis                11  \n",
       "12  https://en.wikipedia.org/wiki/Content_analysis                12  \n",
       "13  https://en.wikipedia.org/wiki/Content_analysis                13  \n",
       "14  https://en.wikipedia.org/wiki/Content_analysis                14  \n",
       "15  https://en.wikipedia.org/wiki/Content_analysis                15  \n",
       "16  https://en.wikipedia.org/wiki/Content_analysis                16  \n",
       "17  https://en.wikipedia.org/wiki/Content_analysis                17  \n",
       "18  https://en.wikipedia.org/wiki/Content_analysis                18  \n",
       "19  https://en.wikipedia.org/wiki/Content_analysis                19  \n",
       "20  https://en.wikipedia.org/wiki/Content_analysis                20  \n",
       "21  https://en.wikipedia.org/wiki/Content_analysis                21  \n",
       "22  https://en.wikipedia.org/wiki/Content_analysis                22  \n",
       "23  https://en.wikipedia.org/wiki/Content_analysis                23  \n",
       "24  https://en.wikipedia.org/wiki/Content_analysis                24  \n",
       "25  https://en.wikipedia.org/wiki/Content_analysis                25  \n",
       "26  https://en.wikipedia.org/wiki/Content_analysis                26  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentParagraphsDF['source'] = [wikipedia_content_analysis] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['paragraph-number'] = range(len(contentParagraphsDF['paragraph-text']))\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a function to parse each linked page and add its text to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "\n",
    "def getTextFromWikiPage(linkTag):\n",
    "    #We need to extract the url from the <a> tag\n",
    "    relurl = linkTag.get('href')\n",
    "    #The urls are relative so we need to prepend the wikipedia url\n",
    "    #while both of them are strings using the specialized function means\n",
    "    #badly formatted relurls will be fixed, if possible\n",
    "    url = urllib.parse.urljoin(wikipedia_base_url, relurl)\n",
    "    #Make a dict to store data before adding it to the DataFrame\n",
    "    parsDict = {'source' : [], 'paragraph-number' : [], 'paragraph-text' : []}\n",
    "    #Now we get the page\n",
    "    r = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #enumerating gives use the paragraph number\n",
    "    for parNum, pTag in enumerate(soup.body.findAll('p')):\n",
    "        #same regex as before\n",
    "        parsDict['paragraph-text'].append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "        parsDict['paragraph-number'].append(parNum)\n",
    "        parsDict['source'].append(url)\n",
    "    return pandas.DataFrame(parsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it on our list of link tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-number</th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Content analysis is \"a wide and heterogeneous ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Content analysis has come to be a sort of 'umb...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Despite the wide variety of options, generally...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>The method of content analysis enables the res...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Since the 1980s, content analysis has become a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>The creation of coding frames is intrinsically...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Mimetic Convergence thus aims to show the proc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Every content analysis should depart from a hy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>As an evaluation approach, content analysis is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Qualitative content analysis is “a systematic,...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>According to Dr. Klaus Krippendorff, six quest...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>The assumption is that words and phrases menti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Qualitatively, content analysis can involve an...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Normally, content analysis can only be applied...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Dermot McKeone highlighted the difference betw...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>As the uncritical use of text is today widely ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Neuendorf suggests that when human coders are ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>In literary theory, a text is any object that ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>Within the field of literary criticism, \"text\"...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>Since the history of writing predates the conc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>The word text has its origins in Quintilian's ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>Relying on literary theory, the notion of text...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paragraph-number                                     paragraph-text  \\\n",
       "0                  0  Content analysis is \"a wide and heterogeneous ...   \n",
       "1                  1  Content analysis has come to be a sort of 'umb...   \n",
       "2                  2  Content analysis can also be described as stud...   \n",
       "3                  3  Despite the wide variety of options, generally...   \n",
       "4                  4  Over the years, content analysis has been appl...   \n",
       "5                  5  In recent times, particularly with the advent ...   \n",
       "6                  6  Quantitative content analysis has enjoyed a re...   \n",
       "7                  7                                                      \n",
       "8                  8                                                      \n",
       "9                  9  The method of content analysis enables the res...   \n",
       "10                10  Since the 1980s, content analysis has become a...   \n",
       "11                11  The creation of coding frames is intrinsically...   \n",
       "12                12  Mimetic Convergence thus aims to show the proc...   \n",
       "13                13  Every content analysis should depart from a hy...   \n",
       "14                14  As an evaluation approach, content analysis is...   \n",
       "15                15  Qualitative content analysis is “a systematic,...   \n",
       "16                16  Holsti groups fifteen uses of content analysis...   \n",
       "17                17  He also places these uses into the context of ...   \n",
       "18                18  The following table shows fifteen uses of cont...   \n",
       "19                19  According to Dr. Klaus Krippendorff, six quest...   \n",
       "20                20  The assumption is that words and phrases menti...   \n",
       "21                21  Qualitatively, content analysis can involve an...   \n",
       "22                22  Normally, content analysis can only be applied...   \n",
       "23                23  A further step in analysis is the distinction ...   \n",
       "24                24  Dermot McKeone highlighted the difference betw...   \n",
       "25                25  As the uncritical use of text is today widely ...   \n",
       "26                26  Neuendorf suggests that when human coders are ...   \n",
       "27                 0  In literary theory, a text is any object that ...   \n",
       "28                 1  Within the field of literary criticism, \"text\"...   \n",
       "29                 2  Since the history of writing predates the conc...   \n",
       "30                 3                                                      \n",
       "31                 4                                                      \n",
       "32                 5  The word text has its origins in Quintilian's ...   \n",
       "33                 6  Relying on literary theory, the notion of text...   \n",
       "\n",
       "                                               source  \n",
       "0      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "1      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "2      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "3      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "4      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "5      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "6      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "7      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "8      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "9      https://en.wikipedia.org/wiki/Content_analysis  \n",
       "10     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "11     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "12     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "13     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "14     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "15     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "16     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "17     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "18     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "19     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "20     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "21     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "22     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "23     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "24     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "25     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "26     https://en.wikipedia.org/wiki/Content_analysis  \n",
       "27  https://en.wikipedia.org/wiki/Text_(literary_t...  \n",
       "28  https://en.wikipedia.org/wiki/Text_(literary_t...  \n",
       "29  https://en.wikipedia.org/wiki/Text_(literary_t...  \n",
       "30  https://en.wikipedia.org/wiki/Text_(literary_t...  \n",
       "31  https://en.wikipedia.org/wiki/Text_(literary_t...  \n",
       "32  https://en.wikipedia.org/wiki/Text_(literary_t...  \n",
       "33  https://en.wikipedia.org/wiki/Text_(literary_t...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for aTag in tagLinks[:1]:\n",
    "    #ignore_index means the indices will not be reset after each append\n",
    "    contentParagraphsDF = contentParagraphsDF.append(getTextFromWikiPage(aTag),ignore_index=True)\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files\n",
    "\n",
    "What if the text we want isn't on a webpage? There are a many other sources of text available.\n",
    "\n",
    "## Raw text\n",
    "\n",
    "The most basic form of storing text is as a _raw text_ document. Source code (`.py`, `.r`, etc) is usually raw text as are text files (`.txt`) and many other things. Opening an unknown file with a text editor is often a great way of learning what the file is.\n",
    "\n",
    "We can create a text file with the `open()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example_text_file = 'sometextfile.txt'\n",
    "#stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols \\u2421 \\u241B \\u20A0 \\u20A1 \\u20A2 \\u20A3 \\u0D60\\n'\n",
    "stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\\n'\n",
    "\n",
    "with open(example_text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(stringToWrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice though the `encoding='utf-8'` argument, the encoding specifies how we map the bits from the file to the glyphs (and whitespace characters like tab (`'\\t'`) or newline (`'\\n'`)) on the screen. When dealing only with latin letters, arabic numerals and the other symbols on America keyboards you usually do not have to worry about encodings as the ones used today are backwards compatible with [ASCII](https://en.wikipedia.org/wiki/ASCII) which gives the binary representation of 128 characters.\n",
    "\n",
    "Some people though use other characters. To solve this there is [Unicode](https://en.wikipedia.org/wiki/Unicode) which gives numbers to symbols, e.g. 041 is `'A'` and 03A3 is `'Σ'` (number starting with 0 indicates they are hexadecimal), often non-ASCII characters are called Unicode characters. Unfortunately there are many ways used to map combinations of bits to Unicode symbols. The ones you are likely to encounter are called by Python _utf-8_, _utf-16_ and _latin-1_. _utf-8_ is the standard for Linux and Mac OS while both _utf-16_ and _latin-1_ are used by windows. If you use the wrong encoding characters can appear wrong, sometimes change in number or Python could raise an exception. Lets see what happens when we open the file we just created with different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is with the correct encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\n",
      "\n",
      "This is with the wrong encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols â¡ â â  â¡ â¢ â£ àµ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(example_text_file, encoding='utf-8') as f:\n",
    "    print(\"This is with the correct encoding:\")\n",
    "    print(f.read())\n",
    "\n",
    "with open(example_text_file, encoding='latin-1') as f:\n",
    "    print(\"This is with the wrong encoding:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with _latin-1_ the unicode characters are mixed up and there are too many of them. You need to keep in mind encoding when obtaining text files, as determining the encoding can sometime be a lot of work.\n",
    "\n",
    "## PDF\n",
    "\n",
    "Another common way text will be stored is in a PDF file. First we will download a pdf in Python. To do that lets grab a chapter from\n",
    "_Speech and Language Processing_, chapter 20 is on Information Extraction which seems apt. It is stored as a pdf at [https://web.stanford.edu/~jurafsky/slp3/20.pdf](https://web.stanford.edu/~jurafsky/slp3/20.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.5\n",
      "%����\n",
      "97 0 obj\n",
      "<<\n",
      "/Length 2982      \n",
      "/Filter /FlateDecode\n",
      ">>\n",
      "stream\n",
      "xڝYY��\u0011~�_��T,U�\u0018\u0012����f<{����Rv\u001e",
      "(\n",
      "���������\u0000Ei���_�F�\u00014�n�s\u000e�缹����_^����Y������\"7\u0004����d��s~^}:i]\u001c",
      "כHE���\t�c�\u001c",
      "���e��k\u000b",
      "��esp�\u001bߋ���yS�Jf\u0018�|�?>���\u0006�׺\u0017�+��y7����==w��8�����\u0013\u0004�M<�x�\n",
      "����`?���Q�\u001f*gs����#C8����8\n",
      "�G�\u001b�(�s#�9�t\u0007�\n",
      "i)s|�͢H\u0011������$�����v��Շ���W[�\u0016��f��{\u001e",
      "�M��M�(�M=gã�\n",
      "�蒟��\b>�\u000e��ڊQn1\u001c",
      "�,�V��י\u0002^wU��Z�\u0019��u���\u000b",
      "\u0019\u0016�b����`��l!�!�+��)��\u000b",
      "\u001a��$����`x+�]XV\u0012�p!\u0013Y>��\u000e�J�\u001f�)\u0014���7��Xʰ��%��\be��M\u0010�ǭ������\u0012�\u0018��\u0007���s;\n",
      "*��\\��o^=���\u001c",
      "���\u0010\u001ad�8��P��P����\u0018@p��^(�&N�[L�d)�H�\u0012����a����\u001awf��\u0011!\u001d",
      "�\b�톁�$(dI\u0011f��h�4���\u0015;J,O��\u0005��4�pI\u001c",
      "�\f",
      "�/\u001bn����\u000b",
      "0�f���\u001d",
      "�\u001d",
      "\u0012\u000b",
      "�:\u0010�!\u0018���\"�L��t�kC��BT�'0[}�)\u001c",
      "|-a�\u0017\u001b��4(\u0011��f��\u0002��ï��w��:�V�-#���\u0017����\tbZ2�\u0004��|ێ� �(\u0001O�e�\u0001��P�.ς!�\n"
     ]
    }
   ],
   "source": [
    "#information_extraction_pdf = 'https://web.stanford.edu/~jurafsky/slp3/20.pdf'\n",
    "\n",
    "infoExtractionRequest = requests.get(information_extraction_pdf)\n",
    "print(infoExtractionRequest.text[:1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
